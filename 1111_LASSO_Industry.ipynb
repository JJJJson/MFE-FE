{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15aa2997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.11.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.11.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.11.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install pandas\n",
    "%conda install statsmodels\n",
    "%conda install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c47828c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "industries_data = pd.read_csv('/Users/jingzhao/Desktop/FE PW1/Data/17 Industry Portfolios.CSV')\n",
    "financial_data = pd.read_csv('/Users/jingzhao/Desktop/FE PW1/Data/Financial Data.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "08d7d4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Trans</td>\n",
       "      <td>1.697930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Steel</td>\n",
       "      <td>1.631720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Finan</td>\n",
       "      <td>1.592452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Durbl</td>\n",
       "      <td>0.792943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oil</td>\n",
       "      <td>0.557602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Utils</td>\n",
       "      <td>0.554351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cars</td>\n",
       "      <td>0.486595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clths</td>\n",
       "      <td>0.475323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food</td>\n",
       "      <td>0.252767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cnstr</td>\n",
       "      <td>-0.031482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chems</td>\n",
       "      <td>-0.268284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mines</td>\n",
       "      <td>-0.443972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cnsum</td>\n",
       "      <td>-0.563302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Rtail</td>\n",
       "      <td>-0.948532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FabPr</td>\n",
       "      <td>-0.962965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Machn</td>\n",
       "      <td>-1.819663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Other</td>\n",
       "      <td>-2.065798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature  Coefficient\n",
       "12   Trans     1.697930\n",
       "8    Steel     1.631720\n",
       "15   Finan     1.592452\n",
       "4    Durbl     0.792943\n",
       "2    Oil       0.557602\n",
       "13   Utils     0.554351\n",
       "11   Cars      0.486595\n",
       "3    Clths     0.475323\n",
       "0    Food      0.252767\n",
       "7    Cnstr    -0.031482\n",
       "5    Chems    -0.268284\n",
       "1    Mines    -0.443972\n",
       "6    Cnsum    -0.563302\n",
       "14   Rtail    -0.948532\n",
       "9    FabPr    -0.962965\n",
       "10   Machn    -1.819663\n",
       "16   Other    -2.065798"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HML: Lasso coefficient\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "merged_data = pd.merge(industries_data, financial_data[['Date', 'HML']], on='Date')\n",
    "X = merged_data.drop(columns=['Date', 'HML'])\n",
    "y = merged_data['HML']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Using LASSO regression with cross-validation to find the best alpha\n",
    "lasso = LassoCV(cv=5, random_state=42)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "y_pred = lasso.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Extracting the coefficients and the selected features\n",
    "lasso_coefs = lasso.coef_\n",
    "selected_features = X.columns[np.abs(lasso_coefs) > 0]\n",
    "\n",
    "selected_features, mse, lasso.alpha_\n",
    "\n",
    "# Creating a DataFrame to display the coefficients and their corresponding features\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': lasso_coefs\n",
    "})\n",
    "\n",
    "# Filtering out the features with zero coefficients\n",
    "significant_coefficients = coefficients[np.abs(coefficients['Coefficient']) > 0]\n",
    "significant_coefficients.sort_values(by='Coefficient', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f5a6e64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0034997229923687725"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimal alpha\n",
    "optimal_alpha = lasso.alpha_\n",
    "optimal_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cdfcb9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Other</td>\n",
       "      <td>-2.065798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Machn</td>\n",
       "      <td>-1.819663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Trans</td>\n",
       "      <td>1.697930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Steel</td>\n",
       "      <td>1.631720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Finan</td>\n",
       "      <td>1.592452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature  Coefficient\n",
       "16   Other    -2.065798\n",
       "10   Machn    -1.819663\n",
       "12   Trans     1.697930\n",
       "8    Steel     1.631720\n",
       "15   Finan     1.592452"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best regressors\n",
    "top_5_features = significant_coefficients.reindex(significant_coefficients.Coefficient.abs().sort_values(ascending=False).index).head(5)\n",
    "top_5_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "18c2b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HML Rolling Regression\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def rolling_regression(data, selected_features, train_years, test_years):\n",
    "    # Convert 'Date' to datetime for easier date manipulation\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "\n",
    "    # Get the unique years in the dataset\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "    \n",
    "    results = []\n",
    "    start_year = unique_years[0]\n",
    "\n",
    "    # Perform rolling regression\n",
    "    while start_year + train_years + test_years <= unique_years[-1]:\n",
    "        # Define training and testing periods\n",
    "        train_start = pd.Timestamp(year=start_year, month=1, day=1)\n",
    "        train_end = train_start + pd.DateOffset(years=train_years)\n",
    "        test_end = train_end + pd.DateOffset(years=test_years)\n",
    "\n",
    "        # Subset the data for training and testing\n",
    "        train_data = data[(data['Date'] >= train_start) & (data['Date'] < train_end)]\n",
    "        test_data = data[(data['Date'] >= train_end) & (data['Date'] < test_end)]\n",
    "\n",
    "        # Fit the model\n",
    "        X_train = train_data[selected_features]\n",
    "        y_train = train_data['HML']\n",
    "        model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "        # Predict on test data\n",
    "        X_test = test_data[selected_features]\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Collect coefficients and predictions\n",
    "        coefficients = model.coef_\n",
    "        results.append({\n",
    "            'train_start': train_start,\n",
    "            'train_end': train_end,\n",
    "            'test_end': test_end,\n",
    "            'coefficients': coefficients,\n",
    "            'predicted_HML': y_pred\n",
    "        })\n",
    "\n",
    "        # Move to the next period\n",
    "        start_year += test_years\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Define the selected features (this should be set based on your specific dataset)\n",
    "selected_features = ['Trans', 'Steel', 'Machn', 'Finan', 'Other']\n",
    "\n",
    "# Rolling regression for each scenario\n",
    "results_5_year = rolling_regression(merged_data, selected_features, train_years=5, test_years=5)\n",
    "results_10_year = rolling_regression(merged_data, selected_features, train_years=10, test_years=5)\n",
    "results_20_year = rolling_regression(merged_data, selected_features, train_years=20, test_years=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ff2be530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta and HML\n",
    "def extract_betas_and_predictions(results):\n",
    "    betas = []\n",
    "    predicted_HML = []\n",
    "\n",
    "    for index, row in results.iterrows():\n",
    "        # Extract beta coefficients\n",
    "        betas.append({\n",
    "            'train_start': row['train_start'],\n",
    "            'train_end': row['train_end'],\n",
    "            'test_end': row['test_end'],\n",
    "            **{f'beta_{i}': coef for i, coef in enumerate(row['coefficients'])}\n",
    "        })\n",
    "        \n",
    "        # Extract predicted HML values\n",
    "        for prediction in row['predicted_HML']:\n",
    "            predicted_HML.append({\n",
    "                'test_end': row['test_end'],\n",
    "                'predicted_HML': prediction\n",
    "            })\n",
    "\n",
    "    betas_df = pd.DataFrame(betas)\n",
    "    predicted_HML_df = pd.DataFrame(predicted_HML)\n",
    "\n",
    "    return betas_df, predicted_HML_df\n",
    "\n",
    "# Process the results for each time scheme\n",
    "betas_5_year, predicted_HML_5_year = extract_betas_and_predictions(results_5_year)\n",
    "betas_10_year, predicted_HML_10_year = extract_betas_and_predictions(results_10_year)\n",
    "betas_20_year, predicted_HML_20_year = extract_betas_and_predictions(results_20_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e9e7f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual\n",
    "def calculate_residuals(data, predicted_HML, train_years, test_years):\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "    residuals = []\n",
    "\n",
    "    start_year = unique_years[0]\n",
    "    predicted_index = 0\n",
    "\n",
    "    while start_year + train_years + test_years <= unique_years[-1]:\n",
    "        # Define the testing period\n",
    "        test_start = pd.Timestamp(year=start_year + train_years, month=1, day=1)\n",
    "        test_end = test_start + timedelta(days=365 * test_years)\n",
    "\n",
    "        # Subset the actual data for the testing period\n",
    "        test_data = data[(data['Date'] >= test_start) & (data['Date'] < test_end)]\n",
    "        actual_HML = test_data['HML'].values\n",
    "\n",
    "        # Calculate residuals\n",
    "        predicted_HML_values = predicted_HML['predicted_HML'].iloc[predicted_index:predicted_index + len(actual_HML)]\n",
    "        residual = actual_HML - predicted_HML_values\n",
    "        residuals.extend(residual)\n",
    "\n",
    "        # Update indices\n",
    "        predicted_index += len(actual_HML)\n",
    "        start_year += test_years\n",
    "\n",
    "    return pd.DataFrame({'residuals': residuals})\n",
    "\n",
    "# Calculate residuals for each rolling scheme\n",
    "residuals_5_year = calculate_residuals(merged_data, predicted_HML_5_year, 5, 5)\n",
    "residuals_10_year = calculate_residuals(merged_data, predicted_HML_10_year, 10, 5)\n",
    "residuals_20_year = calculate_residuals(merged_data, predicted_HML_20_year, 20, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a787503e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         residuals\n",
       " count  1080.000000\n",
       " mean     -0.031597\n",
       " std       2.475316\n",
       " min     -13.710342\n",
       " 25%      -1.332233\n",
       " 50%      -0.075307\n",
       " 75%       1.360415\n",
       " max      10.027822,\n",
       "          residuals\n",
       " count  1020.000000\n",
       " mean     -0.098707\n",
       " std       2.148893\n",
       " min     -13.030419\n",
       " 25%      -1.326080\n",
       " 50%      -0.103802\n",
       " 75%       1.141364\n",
       " max       9.186277,\n",
       "         residuals\n",
       " count  900.000000\n",
       " mean    -0.130205\n",
       " std      2.086146\n",
       " min     -8.466385\n",
       " 25%     -1.372565\n",
       " 50%     -0.163566\n",
       " 75%      1.103427\n",
       " max      8.381515)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Residual Summary\n",
    "residual_summary_5_year = residuals_5_year.describe()\n",
    "residual_summary_10_year = residuals_10_year.describe()\n",
    "residual_summary_20_year = residuals_20_year.describe()\n",
    "\n",
    "residual_summary_5_year, residual_summary_10_year, residual_summary_20_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd83d3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6612.31704619941, 4715.415162630034, 3927.7100470840132)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SSE for each time scheme\n",
    "sse_5_year = np.sum(residuals_5_year['residuals'] ** 2)\n",
    "sse_10_year = np.sum(residuals_10_year['residuals'] ** 2)\n",
    "sse_20_year = np.sum(residuals_20_year['residuals'] ** 2)\n",
    "\n",
    "sse_5_year, sse_10_year, sse_20_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "42c12de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4973857240612507, 0.42530172773361963, 0.4024258908893674)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out-of-sample R-squared\n",
    "def calculate_out_of_sample_r_squared(data, predicted_HML, residuals, train_years, test_years):\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "\n",
    "    total_sum_squares = 0\n",
    "    residual_sum_squares = 0\n",
    "    predicted_index = 0\n",
    "\n",
    "    start_year = unique_years[0]\n",
    "\n",
    "    while start_year + train_years + test_years <= unique_years[-1]:\n",
    "        # Define the testing period\n",
    "        test_start = pd.Timestamp(year=start_year + train_years, month=1, day=1)\n",
    "        test_end = test_start + timedelta(days=365 * test_years)\n",
    "\n",
    "        # Subset the actual data for the testing period\n",
    "        test_data = data[(data['Date'] >= test_start) & (data['Date'] < test_end)]\n",
    "        actual_HML = test_data['HML'].values\n",
    "\n",
    "        # Calculate total sum of squares and residual sum of squares\n",
    "        mean_actual_HML = np.mean(actual_HML)\n",
    "        total_sum_squares += np.sum((actual_HML - mean_actual_HML) ** 2)\n",
    "        residual_sum_squares += np.sum(residuals['residuals'].iloc[predicted_index:predicted_index + len(actual_HML)] ** 2)\n",
    "\n",
    "        # Update indices\n",
    "        predicted_index += len(actual_HML)\n",
    "        start_year += test_years\n",
    "\n",
    "    return 1 - (residual_sum_squares / total_sum_squares)\n",
    "\n",
    "# Calculate out-of-sample R-squared for each rolling scheme\n",
    "r_squared_5_year = calculate_out_of_sample_r_squared(merged_data, predicted_HML_5_year, residuals_5_year, 5, 5)\n",
    "r_squared_10_year = calculate_out_of_sample_r_squared(merged_data, predicted_HML_10_year, residuals_10_year, 10, 5)\n",
    "r_squared_20_year = calculate_out_of_sample_r_squared(merged_data, predicted_HML_20_year, residuals_20_year, 20, 5)\n",
    "\n",
    "r_squared_5_year, r_squared_10_year, r_squared_20_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "facb98e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Finan</td>\n",
       "      <td>-1.873595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Steel</td>\n",
       "      <td>-1.302492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Other</td>\n",
       "      <td>1.178256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clths</td>\n",
       "      <td>-0.881954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cnstr</td>\n",
       "      <td>0.806181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature  Coefficient\n",
       "15   Finan    -1.873595\n",
       "8    Steel    -1.302492\n",
       "16   Other     1.178256\n",
       "3    Clths    -0.881954\n",
       "7    Cnstr     0.806181"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MOM Select Regressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Merging the datasets on the 'Date' column\n",
    "merged_data = pd.merge(industries_data, financial_data[['Date', 'MOM']], on='Date')\n",
    "\n",
    "# Splitting the data into features (X) and target (y)\n",
    "X = merged_data.drop(columns=['Date', 'MOM'])\n",
    "y = merged_data['MOM']\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Using LASSO regression with cross-validation to find the best alpha\n",
    "lasso = LassoCV(cv=5, random_state=42)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "y_pred = lasso.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Extracting the coefficients and the selected features\n",
    "lasso_coefs = lasso.coef_\n",
    "selected_features = X.columns[np.abs(lasso_coefs) > 0]\n",
    "\n",
    "selected_features, mse, lasso.alpha_\n",
    "\n",
    "# Creating a DataFrame to display the coefficients and their corresponding features\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': lasso_coefs\n",
    "})\n",
    "\n",
    "# Filtering out the features with zero coefficients\n",
    "significant_coefficients = coefficients[np.abs(coefficients['Coefficient']) > 0]\n",
    "significant_coefficients.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "top_5_features = significant_coefficients.reindex(significant_coefficients.Coefficient.abs().sort_values(ascending=False).index).head(5)\n",
    "top_5_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "64d196a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOM Rolling Regression\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def rolling_regression(data, selected_features, train_years, test_years):\n",
    "    # Convert 'Date' to datetime for easier date manipulation\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "\n",
    "    # Get the unique years in the dataset\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "    \n",
    "    results = []\n",
    "    start_year = unique_years[0]\n",
    "\n",
    "    # Perform rolling regression\n",
    "    while start_year + train_years + test_years <= unique_years[-1]:\n",
    "        # Define training and testing periods\n",
    "        train_start = pd.Timestamp(year=start_year, month=1, day=1)\n",
    "        train_end = train_start + pd.DateOffset(years=train_years)\n",
    "        test_end = train_end + pd.DateOffset(years=test_years)\n",
    "\n",
    "        # Subset the data for training and testing\n",
    "        train_data = data[(data['Date'] >= train_start) & (data['Date'] < train_end)]\n",
    "        test_data = data[(data['Date'] >= train_end) & (data['Date'] < test_end)]\n",
    "\n",
    "        # Fit the model\n",
    "        X_train = train_data[selected_features]\n",
    "        y_train = train_data['MOM']\n",
    "        model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "        # Predict on test data\n",
    "        X_test = test_data[selected_features]\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Collect coefficients and predictions\n",
    "        coefficients = model.coef_\n",
    "        results.append({\n",
    "            'train_start': train_start,\n",
    "            'train_end': train_end,\n",
    "            'test_end': test_end,\n",
    "            'coefficients': coefficients,\n",
    "            'predicted_MOM': y_pred\n",
    "        })\n",
    "\n",
    "        # Move to the next period\n",
    "        start_year += test_years\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Define the selected features (this should be set based on your specific dataset)\n",
    "selected_features = ['Clths', 'Steel', 'Cnstr', 'Finan', 'Other']\n",
    "\n",
    "# Rolling regression for each scenario\n",
    "results_5_year = rolling_regression(merged_data, selected_features, train_years=5, test_years=5)\n",
    "results_10_year = rolling_regression(merged_data, selected_features, train_years=10, test_years=5)\n",
    "results_20_year = rolling_regression(merged_data, selected_features, train_years=20, test_years=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "866b6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta and HML\n",
    "def extract_betas_and_predictions(results):\n",
    "    betas = []\n",
    "    predicted_MOM = []\n",
    "\n",
    "    for index, row in results.iterrows():\n",
    "        # Extract beta coefficients\n",
    "        betas.append({\n",
    "            'train_start': row['train_start'],\n",
    "            'train_end': row['train_end'],\n",
    "            'test_end': row['test_end'],\n",
    "            **{f'beta_{i}': coef for i, coef in enumerate(row['coefficients'])}\n",
    "        })\n",
    "        \n",
    "        # Extract predicted HML values\n",
    "        for prediction in row['predicted_MOM']:\n",
    "            predicted_MOM.append({\n",
    "                'test_end': row['test_end'],\n",
    "                'predicted_MOM': prediction\n",
    "            })\n",
    "\n",
    "    betas_df = pd.DataFrame(betas)\n",
    "    predicted_MOM_df = pd.DataFrame(predicted_MOM)\n",
    "\n",
    "    return betas_df, predicted_MOM_df\n",
    "\n",
    "# Process the results for each time scheme\n",
    "betas_5_year, predicted_MOM_5_year = extract_betas_and_predictions(results_5_year)\n",
    "betas_10_year, predicted_MOM_10_year = extract_betas_and_predictions(results_10_year)\n",
    "betas_20_year, predicted_MOM_20_year = extract_betas_and_predictions(results_20_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f020df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual\n",
    "def calculate_residuals(data, predicted_MOM, train_years, test_years):\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "    residuals = []\n",
    "\n",
    "    start_year = unique_years[0]\n",
    "    predicted_index = 0\n",
    "\n",
    "    while start_year + train_years + test_years <= unique_years[-1]:\n",
    "        # Define the testing period\n",
    "        test_start = pd.Timestamp(year=start_year + train_years, month=1, day=1)\n",
    "        test_end = test_start + timedelta(days=365 * test_years)\n",
    "\n",
    "        # Subset the actual data for the testing period\n",
    "        test_data = data[(data['Date'] >= test_start) & (data['Date'] < test_end)]\n",
    "        actual_MOM = test_data['MOM'].values\n",
    "\n",
    "        # Calculate residuals\n",
    "        predicted_MOM_values = predicted_MOM['predicted_MOM'].iloc[predicted_index:predicted_index + len(actual_MOM)]\n",
    "        residual = actual_MOM - predicted_MOM_values\n",
    "        residuals.extend(residual)\n",
    "\n",
    "        # Update indices\n",
    "        predicted_index += len(actual_MOM)\n",
    "        start_year += test_years\n",
    "\n",
    "    return pd.DataFrame({'residuals': residuals})\n",
    "\n",
    "# Calculate residuals for each rolling scheme\n",
    "residuals_5_year = calculate_residuals(merged_data, predicted_MOM_5_year, 5, 5)\n",
    "residuals_10_year = calculate_residuals(merged_data, predicted_MOM_10_year, 10, 5)\n",
    "residuals_20_year = calculate_residuals(merged_data, predicted_MOM_20_year, 20, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "af055729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         residuals\n",
       " count  1080.000000\n",
       " mean      0.215367\n",
       " std       4.460510\n",
       " min     -33.975842\n",
       " 25%      -1.655809\n",
       " 50%       0.401647\n",
       " 75%       2.748763\n",
       " max      18.215095,\n",
       "          residuals\n",
       " count  1020.000000\n",
       " mean      0.176491\n",
       " std       4.087025\n",
       " min     -30.014933\n",
       " 25%      -1.593167\n",
       " 50%       0.298243\n",
       " 75%       2.525891\n",
       " max      14.201794,\n",
       "         residuals\n",
       " count  900.000000\n",
       " mean     0.094183\n",
       " std      3.936129\n",
       " min    -30.209998\n",
       " 25%     -1.590653\n",
       " 50%      0.195849\n",
       " 75%      2.341193\n",
       " max     14.534968)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Residual summaries\n",
    "residual_summary_5_year = residuals_5_year.describe()\n",
    "residual_summary_10_year = residuals_10_year.describe()\n",
    "residual_summary_20_year = residuals_20_year.describe()\n",
    "\n",
    "residual_summary_5_year, residual_summary_10_year, residual_summary_20_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3bcbeab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21518.039195379984, 17052.92026996847, 13936.287692297024)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SSE for each time scheme\n",
    "sse_5_year = np.sum(residuals_5_year['residuals'] ** 2)\n",
    "sse_10_year = np.sum(residuals_10_year['residuals'] ** 2)\n",
    "sse_20_year = np.sum(residuals_20_year['residuals'] ** 2)\n",
    "\n",
    "sse_5_year, sse_10_year, sse_20_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "82fba789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05765979016789835, -0.0396814015954885, -0.038007298136080614)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out-of-sample R-squared\n",
    "def calculate_out_of_sample_r_squared(data, predicted_MOM, residuals, train_years, test_years):\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "\n",
    "    total_sum_squares = 0\n",
    "    residual_sum_squares = 0\n",
    "    predicted_index = 0\n",
    "\n",
    "    start_year = unique_years[0]\n",
    "\n",
    "    while start_year + train_years + test_years <= unique_years[-1]:\n",
    "        # Define the testing period\n",
    "        test_start = pd.Timestamp(year=start_year + train_years, month=1, day=1)\n",
    "        test_end = test_start + timedelta(days=365 * test_years)\n",
    "\n",
    "        # Subset the actual data for the testing period\n",
    "        test_data = data[(data['Date'] >= test_start) & (data['Date'] < test_end)]\n",
    "        actual_MOM = test_data['MOM'].values\n",
    "\n",
    "        # Calculate total sum of squares and residual sum of squares\n",
    "        mean_actual_MOM = np.mean(actual_MOM)\n",
    "        total_sum_squares += np.sum((actual_MOM - mean_actual_MOM) ** 2)\n",
    "        residual_sum_squares += np.sum(residuals['residuals'].iloc[predicted_index:predicted_index + len(actual_MOM)] ** 2)\n",
    "\n",
    "        # Update indices\n",
    "        predicted_index += len(actual_MOM)\n",
    "        start_year += test_years\n",
    "\n",
    "    return 1 - (residual_sum_squares / total_sum_squares)\n",
    "\n",
    "# Calculate out-of-sample R-squared for each rolling scheme\n",
    "r_squared_5_year = calculate_out_of_sample_r_squared(merged_data, predicted_MOM_5_year, residuals_5_year, 5, 5)\n",
    "r_squared_10_year = calculate_out_of_sample_r_squared(merged_data, predicted_MOM_10_year, residuals_10_year, 10, 5)\n",
    "r_squared_20_year = calculate_out_of_sample_r_squared(merged_data, predicted_MOM_20_year, residuals_20_year, 20, 5)\n",
    "\n",
    "r_squared_5_year, r_squared_10_year, r_squared_20_year"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
