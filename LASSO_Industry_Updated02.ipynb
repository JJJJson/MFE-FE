{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15aa2997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.11.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.11.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.11.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install pandas\n",
    "%conda install statsmodels\n",
    "%conda install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c47828c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "industries_data = pd.read_csv('/Users/jingzhao/Desktop/FE PW1/Data/17 Industry Portfolios.CSV')\n",
    "financial_data = pd.read_csv('/Users/jingzhao/Desktop/FE PW1/Data/Financial Data.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e15e9681",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Index(['Oil  ', 'Steel', 'Machn', 'Trans', 'Utils', 'Finan', 'Other'], dtype='object'),\n",
       " 11.734255539913724,\n",
       " 0.25)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "merged_data = pd.merge(industries_data, financial_data[['Date', 'HML']], on='Date')\n",
    "X = merged_data.drop(columns=['Date', 'HML'])\n",
    "y = merged_data['HML']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Defining the range of alpha values from 0.25 to 2.5\n",
    "alphas = np.linspace(0.25, 2.5, 100)\n",
    "\n",
    "# Using LASSO regression with cross-validation to find the best alpha within the specified range\n",
    "lasso = LassoCV(alphas=alphas, cv=5, random_state=42)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "y_pred = lasso.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Extracting the coefficients and the selected features\n",
    "lasso_coefs = lasso.coef_\n",
    "selected_features = X.columns[np.abs(lasso_coefs) > 0]\n",
    "\n",
    "# Creating a DataFrame to display the coefficients and their corresponding features\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': lasso_coefs\n",
    "})\n",
    "\n",
    "# Filtering out the features with zero coefficients\n",
    "significant_coefficients = coefficients[np.abs(coefficients['Coefficient']) > 0]\n",
    "significant_coefficients_sorted = significant_coefficients.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Printing the best alpha value\n",
    "print(lasso.alpha_)\n",
    "\n",
    "# Returning the results\n",
    "selected_features, mse, lasso.alpha_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1a92c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HML Rolling Regression\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def rolling_regression(data, selected_features, train_years, test_years):\n",
    "    # Convert 'Date' to datetime for easier date manipulation\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "\n",
    "    # Get the unique years in the dataset\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "    \n",
    "    results = []\n",
    "    start_year = unique_years[0]\n",
    "\n",
    "    # Perform rolling regression\n",
    "    while start_year + train_years + test_years <= unique_years[-1]:\n",
    "        # Define training and testing periods\n",
    "        train_start = pd.Timestamp(year=start_year, month=1, day=1)\n",
    "        train_end = train_start + pd.DateOffset(years=train_years)\n",
    "        test_end = train_end + pd.DateOffset(years=test_years)\n",
    "\n",
    "        # Subset the data for training and testing\n",
    "        train_data = data[(data['Date'] >= train_start) & (data['Date'] < train_end)]\n",
    "        test_data = data[(data['Date'] >= train_end) & (data['Date'] < test_end)]\n",
    "\n",
    "        # Fit the model\n",
    "        X_train = train_data[selected_features]\n",
    "        y_train = train_data['HML']\n",
    "        model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "        # Predict on test data\n",
    "        X_test = test_data[selected_features]\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Collect coefficients and predictions\n",
    "        coefficients = model.coef_\n",
    "        results.append({\n",
    "            'train_start': train_start,\n",
    "            'train_end': train_end,\n",
    "            'test_end': test_end,\n",
    "            'coefficients': coefficients,\n",
    "            'predicted_HML': y_pred\n",
    "        })\n",
    "\n",
    "        # Move to the next period\n",
    "        start_year += test_years\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Rolling regression for each scenario\n",
    "results_5_year = rolling_regression(merged_data, selected_features, train_years=5, test_years=5)\n",
    "results_10_year = rolling_regression(merged_data, selected_features, train_years=10, test_years=5)\n",
    "results_20_year = rolling_regression(merged_data, selected_features, train_years=20, test_years=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ff2be530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta and HML\n",
    "def extract_betas_and_predictions(results):\n",
    "    betas = []\n",
    "    predicted_HML = []\n",
    "\n",
    "    for index, row in results.iterrows():\n",
    "        # Extract beta coefficients\n",
    "        betas.append({\n",
    "            'train_start': row['train_start'],\n",
    "            'train_end': row['train_end'],\n",
    "            'test_end': row['test_end'],\n",
    "            **{f'beta_{i}': coef for i, coef in enumerate(row['coefficients'])}\n",
    "        })\n",
    "        \n",
    "        # Extract predicted HML values\n",
    "        for prediction in row['predicted_HML']:\n",
    "            predicted_HML.append({\n",
    "                'test_end': row['test_end'],\n",
    "                'predicted_HML': prediction\n",
    "            })\n",
    "\n",
    "    betas_df = pd.DataFrame(betas)\n",
    "    predicted_HML_df = pd.DataFrame(predicted_HML)\n",
    "\n",
    "    return betas_df, predicted_HML_df\n",
    "\n",
    "# Process the results for each time scheme\n",
    "betas_5_year, predicted_HML_5_year = extract_betas_and_predictions(results_5_year)\n",
    "betas_10_year, predicted_HML_10_year = extract_betas_and_predictions(results_10_year)\n",
    "betas_20_year, predicted_HML_20_year = extract_betas_and_predictions(results_20_year)\n",
    "\n",
    "df = pd.DataFrame(betas_5_year)\n",
    "df.to_csv('/Users/jingzhao/Desktop/Lasso_HML_Beta_5yr.csv', index=False)\n",
    "df = pd.DataFrame(betas_10_year)\n",
    "df.to_csv('/Users/jingzhao/Desktop/Lasso_HML_Beta_10yr.csv', index=False)\n",
    "df = pd.DataFrame(betas_20_year)\n",
    "df.to_csv('/Users/jingzhao/Desktop/Lasso_HML_Beta_20yr.csv', index=False)\n",
    "df = pd.DataFrame(predicted_HML_5_year)\n",
    "df.to_csv('/Users/jingzhao/Desktop/Lasso_HML_5yr.csv', index=False)\n",
    "df = pd.DataFrame(predicted_HML_10_year)\n",
    "df.to_csv('/Users/jingzhao/Desktop/Lasso_HML_10yr.csv', index=False)\n",
    "df = pd.DataFrame(predicted_HML_20_year)\n",
    "df.to_csv('/Users/jingzhao/Desktop/Lasso_HML_20yr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d461ef65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      residuals\n",
      "0      2.121167\n",
      "1      0.454468\n",
      "2      1.947860\n",
      "3      8.584469\n",
      "4      6.177617\n",
      "...         ...\n",
      "1075   1.321492\n",
      "1076  -1.392556\n",
      "1077  -2.647062\n",
      "1078   1.692250\n",
      "1079   1.056309\n",
      "\n",
      "[1080 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Residual\n",
    "def calculate_residuals(data, predicted_HML, train_years, test_years):\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "    residuals = []\n",
    "\n",
    "    start_year = unique_years[0]\n",
    "    predicted_index = 0\n",
    "\n",
    "    while start_year + train_years + test_years <= unique_years[-1]:\n",
    "        # Define the testing period\n",
    "        test_start = pd.Timestamp(year=start_year + train_years, month=1, day=1)\n",
    "        test_end = test_start + timedelta(days=365 * test_years)\n",
    "\n",
    "        # Subset the actual data for the testing period\n",
    "        test_data = data[(data['Date'] >= test_start) & (data['Date'] < test_end)]\n",
    "        actual_HML = test_data['HML'].values\n",
    "\n",
    "        # Calculate residuals\n",
    "        predicted_HML_values = predicted_HML['predicted_HML'].iloc[predicted_index:predicted_index + len(actual_HML)]\n",
    "        residual = actual_HML - predicted_HML_values\n",
    "        residuals.extend(residual)\n",
    "\n",
    "        # Update indices\n",
    "        predicted_index += len(actual_HML)\n",
    "        start_year += test_years\n",
    "\n",
    "    return pd.DataFrame({'residuals': residuals})\n",
    "\n",
    "# Calculate residuals for each rolling scheme\n",
    "residuals_5_year = calculate_residuals(merged_data, predicted_HML_5_year, 5, 5)\n",
    "residuals_10_year = calculate_residuals(merged_data, predicted_HML_10_year, 10, 5)\n",
    "residuals_20_year = calculate_residuals(merged_data, predicted_HML_20_year, 20, 5)\n",
    "print(residuals_5_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a787503e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         residuals\n",
       " count  1080.000000\n",
       " mean     -0.042134\n",
       " std       2.537738\n",
       " min     -13.728851\n",
       " 25%      -1.367910\n",
       " 50%      -0.065902\n",
       " 75%       1.293495\n",
       " max      13.414780,\n",
       "          residuals\n",
       " count  1020.000000\n",
       " mean     -0.110974\n",
       " std       2.203279\n",
       " min     -13.152560\n",
       " 25%      -1.327086\n",
       " 50%      -0.111770\n",
       " 75%       1.094010\n",
       " max      10.164155,\n",
       "         residuals\n",
       " count  900.000000\n",
       " mean    -0.141301\n",
       " std      2.083290\n",
       " min     -7.958529\n",
       " 25%     -1.402310\n",
       " 50%     -0.247082\n",
       " 75%      1.008806\n",
       " max      8.629615)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Residual Summary\n",
    "residual_summary_5_year = residuals_5_year.describe()\n",
    "residual_summary_10_year = residuals_10_year.describe()\n",
    "residual_summary_20_year = residuals_20_year.describe()\n",
    "\n",
    "residual_summary_5_year, residual_summary_10_year, residual_summary_20_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "dd83d3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6950.798327743153, 4959.232271730891, 3919.717218009812)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SSE for each time scheme\n",
    "sse_5_year = np.sum(residuals_5_year['residuals'] ** 2)\n",
    "sse_10_year = np.sum(residuals_10_year['residuals'] ** 2)\n",
    "sse_20_year = np.sum(residuals_20_year['residuals'] ** 2)\n",
    "\n",
    "sse_5_year, sse_10_year, sse_20_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "411cd069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8582230972238319, 0.8693620049604108, 0.8753761757663567)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HML OOSR2\n",
    "def calculate_out_of_sample_r_squared(data, predicted_HML, residuals, train_years, test_years):\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "\n",
    "    total_sum_squares = 0\n",
    "    residual_sum_squares = 0\n",
    "    predicted_index = 0\n",
    "\n",
    "    for start_year in unique_years:\n",
    "        if start_year + train_years + test_years > unique_years[-1]:\n",
    "            break\n",
    "\n",
    "        # Define the testing period\n",
    "        test_start = pd.Timestamp(year=start_year + train_years, month=1, day=1)\n",
    "        test_end = test_start + timedelta(days=365 * test_years)\n",
    "\n",
    "        # Subset the actual data for the testing period\n",
    "        test_data = data[(data['Date'] >= test_start) & (data['Date'] < test_end)]\n",
    "        actual_HML = test_data['HML'].values\n",
    "\n",
    "        # Calculate total sum of squares and residual sum of squares\n",
    "        mean_actual_HML = np.mean(actual_HML)\n",
    "        total_sum_squares += np.sum((actual_HML - mean_actual_HML) ** 2)\n",
    "        residual_sum_squares += np.sum(residuals['residuals'].iloc[predicted_index:predicted_index + len(actual_HML)] ** 2)\n",
    "\n",
    "        # Update indices\n",
    "        predicted_index += len(actual_HML)\n",
    "\n",
    "    return 1 - (residual_sum_squares / total_sum_squares)\n",
    "\n",
    "# Calculate out-of-sample R-squared for each rolling scheme\n",
    "r_squared_5_year = calculate_out_of_sample_r_squared(merged_data, predicted_HML_5_year, residuals_5_year, 5, 5)\n",
    "r_squared_10_year = calculate_out_of_sample_r_squared(merged_data, predicted_HML_10_year, residuals_10_year, 10, 5)\n",
    "r_squared_20_year = calculate_out_of_sample_r_squared(merged_data, predicted_HML_20_year, residuals_20_year, 20, 5)\n",
    "r_squared_5_year, r_squared_10_year, r_squared_20_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "22c6819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Index(['Clths', 'Steel', 'Cars ', 'Trans', 'Finan'], dtype='object'),\n",
       " 27.4029756661363,\n",
       " 0.25)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MOM Select Regressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "merged_data = pd.merge(industries_data, financial_data[['Date', 'MOM']], on='Date')\n",
    "X = merged_data.drop(columns=['Date', 'MOM'])\n",
    "y = merged_data['MOM']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Defining the range of alpha values from 0.25 to 2.5\n",
    "alphas = np.linspace(0.25, 2.5, 100)\n",
    "\n",
    "# Using LASSO regression with cross-validation to find the best alpha within the specified range\n",
    "lasso = LassoCV(alphas=alphas, cv=5, random_state=42)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "y_pred = lasso.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Extracting the coefficients and the selected features\n",
    "lasso_coefs = lasso.coef_\n",
    "selected_features = X.columns[np.abs(lasso_coefs) > 0]\n",
    "\n",
    "# Creating a DataFrame to display the coefficients and their corresponding features\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': lasso_coefs\n",
    "})\n",
    "\n",
    "# Filtering out the features with zero coefficients\n",
    "significant_coefficients = coefficients[np.abs(coefficients['Coefficient']) > 0]\n",
    "significant_coefficients_sorted = significant_coefficients.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Printing the best alpha value\n",
    "print(lasso.alpha_)\n",
    "\n",
    "# Returning the results\n",
    "selected_features, mse, lasso.alpha_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "64d196a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOM Rolling Regression\n",
    "def rolling_regression(data, selected_features, train_years, test_years):\n",
    "    # Convert 'Date' to datetime for easier date manipulation\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "\n",
    "    # Get the unique years in the dataset\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "    \n",
    "    results = []\n",
    "    start_year = unique_years[0]\n",
    "\n",
    "    # Perform rolling regression\n",
    "    while start_year + train_years + test_years <= unique_years[-1]:\n",
    "        # Define training and testing periods\n",
    "        train_start = pd.Timestamp(year=start_year, month=1, day=1)\n",
    "        train_end = train_start + pd.DateOffset(years=train_years)\n",
    "        test_end = train_end + pd.DateOffset(years=test_years)\n",
    "\n",
    "        # Subset the data for training and testing\n",
    "        train_data = data[(data['Date'] >= train_start) & (data['Date'] < train_end)]\n",
    "        test_data = data[(data['Date'] >= train_end) & (data['Date'] < test_end)]\n",
    "\n",
    "        # Fit the model\n",
    "        X_train = train_data[selected_features]\n",
    "        y_train = train_data['MOM']\n",
    "        model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "        # Predict on test data\n",
    "        X_test = test_data[selected_features]\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Collect coefficients and predictions\n",
    "        coefficients = model.coef_\n",
    "        results.append({\n",
    "            'train_start': train_start,\n",
    "            'train_end': train_end,\n",
    "            'test_end': test_end,\n",
    "            'coefficients': coefficients,\n",
    "            'predicted_MOM': y_pred\n",
    "        })\n",
    "\n",
    "        # Move to the next period\n",
    "        start_year += test_years\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Rolling regression for each scenario\n",
    "results_5_year = rolling_regression(merged_data, selected_features, train_years=5, test_years=5)\n",
    "results_10_year = rolling_regression(merged_data, selected_features, train_years=10, test_years=5)\n",
    "results_20_year = rolling_regression(merged_data, selected_features, train_years=20, test_years=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "866b6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta and MOM\n",
    "def extract_betas_and_predictions(results):\n",
    "    betas = []\n",
    "    predicted_MOM = []\n",
    "\n",
    "    for index, row in results.iterrows():\n",
    "        # Extract beta coefficients\n",
    "        betas.append({\n",
    "            'train_start': row['train_start'],\n",
    "            'train_end': row['train_end'],\n",
    "            'test_end': row['test_end'],\n",
    "            **{f'beta_{i}': coef for i, coef in enumerate(row['coefficients'])}\n",
    "        })\n",
    "        \n",
    "        # Extract predicted MOM values\n",
    "        for prediction in row['predicted_MOM']:\n",
    "            predicted_MOM.append({\n",
    "                'test_end': row['test_end'],\n",
    "                'predicted_MOM': prediction\n",
    "            })\n",
    "\n",
    "    betas_df = pd.DataFrame(betas)\n",
    "    predicted_MOM_df = pd.DataFrame(predicted_MOM)\n",
    "\n",
    "    return betas_df, predicted_MOM_df\n",
    "\n",
    "# Process the results for each time scheme\n",
    "betas_5_year, predicted_MOM_5_year = extract_betas_and_predictions(results_5_year)\n",
    "betas_10_year, predicted_MOM_10_year = extract_betas_and_predictions(results_10_year)\n",
    "betas_20_year, predicted_MOM_20_year = extract_betas_and_predictions(results_20_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f020df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual\n",
    "def calculate_residuals(data, predicted_MOM, train_years, test_years):\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "    residuals = []\n",
    "\n",
    "    start_year = unique_years[0]\n",
    "    predicted_index = 0\n",
    "\n",
    "    while start_year + train_years + test_years <= unique_years[-1]:\n",
    "        # Define the testing period\n",
    "        test_start = pd.Timestamp(year=start_year + train_years, month=1, day=1)\n",
    "        test_end = test_start + timedelta(days=365 * test_years)\n",
    "\n",
    "        # Subset the actual data for the testing period\n",
    "        test_data = data[(data['Date'] >= test_start) & (data['Date'] < test_end)]\n",
    "        actual_MOM = test_data['MOM'].values\n",
    "\n",
    "        # Calculate residuals\n",
    "        predicted_MOM_values = predicted_MOM['predicted_MOM'].iloc[predicted_index:predicted_index + len(actual_MOM)]\n",
    "        residual = actual_MOM - predicted_MOM_values\n",
    "        residuals.extend(residual)\n",
    "\n",
    "        # Update indices\n",
    "        predicted_index += len(actual_MOM)\n",
    "        start_year += test_years\n",
    "\n",
    "    return pd.DataFrame({'residuals': residuals})\n",
    "\n",
    "# Calculate residuals for each rolling scheme\n",
    "residuals_5_year = calculate_residuals(merged_data, predicted_MOM_5_year, 5, 5)\n",
    "residuals_10_year = calculate_residuals(merged_data, predicted_MOM_10_year, 10, 5)\n",
    "residuals_20_year = calculate_residuals(merged_data, predicted_MOM_20_year, 20, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "af055729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         residuals\n",
       " count  1080.000000\n",
       " mean      0.488007\n",
       " std       4.920040\n",
       " min     -35.485383\n",
       " 25%      -1.745210\n",
       " 50%       0.716320\n",
       " 75%       3.334757\n",
       " max      16.416958,\n",
       "          residuals\n",
       " count  1020.000000\n",
       " mean      0.403584\n",
       " std       4.389237\n",
       " min     -25.236305\n",
       " 25%      -1.549850\n",
       " 50%       0.569789\n",
       " 75%       2.989516\n",
       " max      14.434734,\n",
       "         residuals\n",
       " count  900.000000\n",
       " mean     0.240018\n",
       " std      4.140386\n",
       " min    -26.982898\n",
       " 25%     -1.628540\n",
       " 50%      0.294478\n",
       " 75%      2.526104\n",
       " max     16.632041)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Residual summaries\n",
    "residual_summary_5_year = residuals_5_year.describe()\n",
    "residual_summary_10_year = residuals_10_year.describe()\n",
    "residual_summary_20_year = residuals_20_year.describe()\n",
    "\n",
    "residual_summary_5_year, residual_summary_10_year, residual_summary_20_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3bcbeab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26376.327655018493, 19797.583460893133, 15463.220625138372)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SSE for each time scheme\n",
    "sse_5_year = np.sum(residuals_5_year['residuals'] ** 2)\n",
    "sse_10_year = np.sum(residuals_10_year['residuals'] ** 2)\n",
    "sse_20_year = np.sum(residuals_20_year['residuals'] ** 2)\n",
    "\n",
    "sse_5_year, sse_10_year, sse_20_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "82fba789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7051126639018661, 0.7332057629178734, 0.7606087359070746)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MOM: OOSR2\n",
    "def calculate_out_of_sample_r_squared(data, predicted_MOM, residuals, train_years, test_years):\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "\n",
    "    total_sum_squares = 0\n",
    "    residual_sum_squares = 0\n",
    "    predicted_index = 0\n",
    "\n",
    "    for start_year in unique_years:\n",
    "        if start_year + train_years + test_years > unique_years[-1]:\n",
    "            break\n",
    "\n",
    "        # Define the testing period\n",
    "        test_start = pd.Timestamp(year=start_year + train_years, month=1, day=1)\n",
    "        test_end = test_start + timedelta(days=365 * test_years)\n",
    "\n",
    "        # Subset the actual data for the testing period\n",
    "        test_data = data[(data['Date'] >= test_start) & (data['Date'] < test_end)]\n",
    "        actual_MOM = test_data['MOM'].values\n",
    "\n",
    "        # Calculate total sum of squares and residual sum of squares\n",
    "        mean_actual_MOM = np.mean(actual_MOM)\n",
    "        total_sum_squares += np.sum((actual_MOM - mean_actual_MOM) ** 2)\n",
    "        residual_sum_squares += np.sum(residuals['residuals'].iloc[predicted_index:predicted_index + len(actual_MOM)] ** 2)\n",
    "\n",
    "        # Update indices\n",
    "        predicted_index += len(actual_MOM)\n",
    "\n",
    "    return 1 - (residual_sum_squares / total_sum_squares)\n",
    "\n",
    "# Calculate out-of-sample R-squared for each rolling scheme\n",
    "r_squared_5_year = calculate_out_of_sample_r_squared(merged_data, predicted_MOM_5_year, residuals_5_year, 5, 5)\n",
    "r_squared_10_year = calculate_out_of_sample_r_squared(merged_data, predicted_MOM_10_year, residuals_10_year, 10, 5)\n",
    "r_squared_20_year = calculate_out_of_sample_r_squared(merged_data, predicted_MOM_20_year, residuals_20_year, 20, 5)\n",
    "r_squared_5_year, r_squared_10_year, r_squared_20_year"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
