{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d19622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.11.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/jingzhao/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas\n",
      "\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  pandas                              2.0.3-py311hdb55bb0_0 --> 2.1.4-py311hdb55bb0_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d2c221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.11.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e6ce7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.11.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f85e283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "industry_portfolio_data = pd.read_csv('/Users/jingzhao/Desktop/FE PW1/Data/17 Industry Portfolios.CSV')\n",
    "financial_data = pd.read_csv('/Users/jingzhao/Desktop/FE PW1/Data/Financial Data.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4bb54a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HML: Regressor Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Data Construction\n",
    "merged_data = pd.merge(industry_portfolio_data, financial_data[['Date', 'HML']], on='Date')\n",
    "missing_values = merged_data.isnull().sum()\n",
    "\n",
    "# Preparing the data for the model\n",
    "X = merged_data.drop(['Date', 'HML'], axis=1)\n",
    "y = merged_data['HML']\n",
    "\n",
    "# Random Forest Model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Feature importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "11a3b1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HML</td>       <th>  R-squared (uncentered):</th>      <td>   0.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   23.63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 Jan 2024</td> <th>  Prob (F-statistic):</th>          <td>4.89e-61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:14:15</td>     <th>  Log-Likelihood:    </th>          <td> -2115.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   930</td>      <th>  AIC:               </th>          <td>   4266.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   913</td>      <th>  BIC:               </th>          <td>   4348.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Trans</th> <td>    0.3061</td> <td>    0.055</td> <td>    5.575</td> <td> 0.000</td> <td>    0.198</td> <td>    0.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Steel</th> <td>    0.1786</td> <td>    0.034</td> <td>    5.249</td> <td> 0.000</td> <td>    0.112</td> <td>    0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Machn</th> <td>   -0.2467</td> <td>    0.035</td> <td>   -7.058</td> <td> 0.000</td> <td>   -0.315</td> <td>   -0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Finan</th> <td>    0.2965</td> <td>    0.051</td> <td>    5.802</td> <td> 0.000</td> <td>    0.196</td> <td>    0.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Other</th> <td>   -0.4167</td> <td>    0.066</td> <td>   -6.299</td> <td> 0.000</td> <td>   -0.546</td> <td>   -0.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Oil  </th> <td>    0.0688</td> <td>    0.031</td> <td>    2.192</td> <td> 0.028</td> <td>    0.007</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cnsum</th> <td>   -0.0969</td> <td>    0.045</td> <td>   -2.129</td> <td> 0.033</td> <td>   -0.186</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rtail</th> <td>   -0.1563</td> <td>    0.041</td> <td>   -3.811</td> <td> 0.000</td> <td>   -0.237</td> <td>   -0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Utils</th> <td>    0.1072</td> <td>    0.035</td> <td>    3.094</td> <td> 0.002</td> <td>    0.039</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Durbl</th> <td>    0.1272</td> <td>    0.046</td> <td>    2.789</td> <td> 0.005</td> <td>    0.038</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FabPr</th> <td>   -0.1727</td> <td>    0.037</td> <td>   -4.636</td> <td> 0.000</td> <td>   -0.246</td> <td>   -0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clths</th> <td>    0.0200</td> <td>    0.065</td> <td>    0.307</td> <td> 0.759</td> <td>   -0.107</td> <td>    0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chems</th> <td>   -0.0708</td> <td>    0.035</td> <td>   -2.011</td> <td> 0.044</td> <td>   -0.140</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mines</th> <td>   -0.0428</td> <td>    0.024</td> <td>   -1.812</td> <td> 0.070</td> <td>   -0.089</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cars </th> <td>    0.0581</td> <td>    0.025</td> <td>    2.303</td> <td> 0.021</td> <td>    0.009</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Food </th> <td>    0.0279</td> <td>    0.056</td> <td>    0.498</td> <td> 0.618</td> <td>   -0.082</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cnstr</th> <td>   -0.0141</td> <td>    0.045</td> <td>   -0.312</td> <td> 0.755</td> <td>   -0.103</td> <td>    0.074</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>61.314</td> <th>  Durbin-Watson:     </th> <td>   1.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 172.523</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.309</td> <th>  Prob(JB):          </th> <td>3.44e-38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.018</td> <th>  Cond. No.          </th> <td>    14.2</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       HML        & \\textbf{  R-squared (uncentered):}      &     0.568   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.559   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       }          &     23.63   \\\\\n",
       "\\textbf{Date:}             & Sat, 06 Jan 2024 & \\textbf{  Prob (F-statistic):}          &  4.89e-61   \\\\\n",
       "\\textbf{Time:}             &     14:14:15     & \\textbf{  Log-Likelihood:    }          &   -2115.8   \\\\\n",
       "\\textbf{No. Observations:} &         930      & \\textbf{  AIC:               }          &     4266.   \\\\\n",
       "\\textbf{Df Residuals:}     &         913      & \\textbf{  BIC:               }          &     4348.   \\\\\n",
       "\\textbf{Df Model:}         &          17      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}  &       HC3        & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Trans} &       0.3061  &        0.055     &     5.575  &         0.000        &        0.198    &        0.414     \\\\\n",
       "\\textbf{Steel} &       0.1786  &        0.034     &     5.249  &         0.000        &        0.112    &        0.245     \\\\\n",
       "\\textbf{Machn} &      -0.2467  &        0.035     &    -7.058  &         0.000        &       -0.315    &       -0.178     \\\\\n",
       "\\textbf{Finan} &       0.2965  &        0.051     &     5.802  &         0.000        &        0.196    &        0.397     \\\\\n",
       "\\textbf{Other} &      -0.4167  &        0.066     &    -6.299  &         0.000        &       -0.546    &       -0.287     \\\\\n",
       "\\textbf{Oil  } &       0.0688  &        0.031     &     2.192  &         0.028        &        0.007    &        0.130     \\\\\n",
       "\\textbf{Cnsum} &      -0.0969  &        0.045     &    -2.129  &         0.033        &       -0.186    &       -0.008     \\\\\n",
       "\\textbf{Rtail} &      -0.1563  &        0.041     &    -3.811  &         0.000        &       -0.237    &       -0.076     \\\\\n",
       "\\textbf{Utils} &       0.1072  &        0.035     &     3.094  &         0.002        &        0.039    &        0.175     \\\\\n",
       "\\textbf{Durbl} &       0.1272  &        0.046     &     2.789  &         0.005        &        0.038    &        0.217     \\\\\n",
       "\\textbf{FabPr} &      -0.1727  &        0.037     &    -4.636  &         0.000        &       -0.246    &       -0.100     \\\\\n",
       "\\textbf{Clths} &       0.0200  &        0.065     &     0.307  &         0.759        &       -0.107    &        0.147     \\\\\n",
       "\\textbf{Chems} &      -0.0708  &        0.035     &    -2.011  &         0.044        &       -0.140    &       -0.002     \\\\\n",
       "\\textbf{Mines} &      -0.0428  &        0.024     &    -1.812  &         0.070        &       -0.089    &        0.003     \\\\\n",
       "\\textbf{Cars } &       0.0581  &        0.025     &     2.303  &         0.021        &        0.009    &        0.108     \\\\\n",
       "\\textbf{Food } &       0.0279  &        0.056     &     0.498  &         0.618        &       -0.082    &        0.138     \\\\\n",
       "\\textbf{Cnstr} &      -0.0141  &        0.045     &    -0.312  &         0.755        &       -0.103    &        0.074     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 61.314 & \\textbf{  Durbin-Watson:     } &    1.912  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &  172.523  \\\\\n",
       "\\textbf{Skew:}          &  0.309 & \\textbf{  Prob(JB):          } & 3.44e-38  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.018 & \\textbf{  Cond. No.          } &     14.2  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                    HML   R-squared (uncentered):                   0.568\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.559\n",
       "Method:                 Least Squares   F-statistic:                              23.63\n",
       "Date:                Sat, 06 Jan 2024   Prob (F-statistic):                    4.89e-61\n",
       "Time:                        14:14:15   Log-Likelihood:                         -2115.8\n",
       "No. Observations:                 930   AIC:                                      4266.\n",
       "Df Residuals:                     913   BIC:                                      4348.\n",
       "Df Model:                          17                                                  \n",
       "Covariance Type:                  HC3                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Trans          0.3061      0.055      5.575      0.000       0.198       0.414\n",
       "Steel          0.1786      0.034      5.249      0.000       0.112       0.245\n",
       "Machn         -0.2467      0.035     -7.058      0.000      -0.315      -0.178\n",
       "Finan          0.2965      0.051      5.802      0.000       0.196       0.397\n",
       "Other         -0.4167      0.066     -6.299      0.000      -0.546      -0.287\n",
       "Oil            0.0688      0.031      2.192      0.028       0.007       0.130\n",
       "Cnsum         -0.0969      0.045     -2.129      0.033      -0.186      -0.008\n",
       "Rtail         -0.1563      0.041     -3.811      0.000      -0.237      -0.076\n",
       "Utils          0.1072      0.035      3.094      0.002       0.039       0.175\n",
       "Durbl          0.1272      0.046      2.789      0.005       0.038       0.217\n",
       "FabPr         -0.1727      0.037     -4.636      0.000      -0.246      -0.100\n",
       "Clths          0.0200      0.065      0.307      0.759      -0.107       0.147\n",
       "Chems         -0.0708      0.035     -2.011      0.044      -0.140      -0.002\n",
       "Mines         -0.0428      0.024     -1.812      0.070      -0.089       0.003\n",
       "Cars           0.0581      0.025      2.303      0.021       0.009       0.108\n",
       "Food           0.0279      0.056      0.498      0.618      -0.082       0.138\n",
       "Cnstr         -0.0141      0.045     -0.312      0.755      -0.103       0.074\n",
       "==============================================================================\n",
       "Omnibus:                       61.314   Durbin-Watson:                   1.912\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              172.523\n",
       "Skew:                           0.309   Prob(JB):                     3.44e-38\n",
       "Kurtosis:                       5.018   Cond. No.                         14.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors are heteroscedasticity robust (HC3)\n",
       "\"\"\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HML: Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "selected_features = feature_importances['Feature'].tolist()\n",
    "\n",
    "# Preparing the data with selected features\n",
    "X_selected = merged_data[selected_features]\n",
    "\n",
    "# Splitting the data into training and testing sets for the selected features\n",
    "X_train_selected, X_test_selected, y_train_selected, y_test_selected = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating and fitting the Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_selected, y_train_selected)\n",
    "\n",
    "# Making predictions and evaluating the model\n",
    "y_pred_selected = lr_model.predict(X_test_selected)\n",
    "mse_selected = mean_squared_error(y_test_selected, y_pred_selected)\n",
    "rmse_selected = np.sqrt(mse_selected)\n",
    "\n",
    "# Output the model performance\n",
    "mse_selected, rmse_selected\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Creating and fitting the OLS model\n",
    "## NOTE: Covariance type is changed to hetero-robust instead of homo\n",
    "ols_model = sm.OLS(y_train_selected, X_train_selected).fit(cov_type='HC3')\n",
    "\n",
    "# Printing the summary of the OLS model\n",
    "ols_summary = ols_model.summary()\n",
    "ols_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "55f96622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   train_start  train_end   test_end  Food_beta  Mines_beta  Oil_beta  \\\n",
       " 0   1927-01-01 1931-12-31 1936-12-29   0.225737   -0.019864  0.175299   \n",
       " 1   1932-01-01 1936-12-30 1941-12-29  -0.192584   -0.054609  0.119764   \n",
       " 2   1937-01-01 1941-12-31 1946-12-30   0.131484   -0.039389  0.301208   \n",
       " 3   1942-01-01 1946-12-31 1951-12-30  -0.118150    0.063429  0.155608   \n",
       " 4   1947-01-01 1951-12-31 1956-12-29   0.107808    0.112041  0.144859   \n",
       " 5   1952-01-01 1956-12-30 1961-12-29   0.292075    0.010123 -0.023117   \n",
       " 6   1957-01-01 1961-12-31 1966-12-30  -0.204629    0.007674  0.025773   \n",
       " 7   1962-01-01 1966-12-31 1971-12-30   0.285842   -0.026342  0.327466   \n",
       " 8   1967-01-01 1971-12-31 1976-12-29  -0.189294   -0.120569  0.129331   \n",
       " 9   1972-01-01 1976-12-30 1981-12-29  -0.051847    0.009850 -0.286878   \n",
       " 10  1977-01-01 1981-12-31 1986-12-30   0.179347   -0.193840 -0.095422   \n",
       " 11  1982-01-01 1986-12-31 1991-12-30  -0.059533    0.012330  0.094594   \n",
       " 12  1987-01-01 1991-12-31 1996-12-29   0.046074   -0.051666  0.150034   \n",
       " 13  1992-01-01 1996-12-30 2001-12-29  -0.050779   -0.048860 -0.053010   \n",
       " 14  1997-01-01 2001-12-31 2006-12-30  -0.121857   -0.057256 -0.047525   \n",
       " 15  2002-01-01 2006-12-31 2011-12-30   0.080025    0.034448  0.044741   \n",
       " 16  2007-01-01 2011-12-31 2016-12-29   0.261304   -0.052819 -0.019558   \n",
       " 17  2012-01-01 2016-12-30 2021-12-29   0.131545   -0.023712  0.233305   \n",
       " \n",
       "     Clths_beta  Durbl_beta  Chems_beta  Cnsum_beta  Cnstr_beta  Steel_beta  \\\n",
       " 0    -0.068459    0.012444   -0.190960    0.034996    0.223597    0.073096   \n",
       " 1     0.139541    0.108246   -0.136441   -0.033600   -0.176381    0.445967   \n",
       " 2     0.110064    0.184232   -0.424470   -0.032542   -0.124745    0.171505   \n",
       " 3    -0.183323    0.258223   -0.372595    0.034473    0.032597    0.020121   \n",
       " 4     0.077085   -0.078687   -0.063126   -0.034028   -0.054881    0.138521   \n",
       " 5     0.124678    0.095339   -0.097321   -0.097658   -0.001671    0.171587   \n",
       " 6     0.270211   -0.033914    0.105380   -0.123820   -0.172420    0.122708   \n",
       " 7     0.113887   -0.187185   -0.052106   -0.139009   -0.145256    0.407633   \n",
       " 8     0.031836   -0.122374    0.035921   -0.257203    0.189576    0.273995   \n",
       " 9     0.136455   -0.065273   -0.141415   -0.321081   -0.450308    0.445528   \n",
       " 10    0.083624   -0.220570   -0.086069   -0.190425    0.336887    0.262293   \n",
       " 11   -0.310713    0.135841   -0.059518   -0.002085   -0.096988    0.144713   \n",
       " 12   -0.105330    0.012530   -0.052033   -0.367526   -0.000542    0.118538   \n",
       " 13   -0.055538    0.173750    0.026470   -0.167029    0.141809    0.000580   \n",
       " 14    0.051264    0.098912    0.109668   -0.028905    0.091117    0.032755   \n",
       " 15   -0.107441    0.129934   -0.111875   -0.107553   -0.102225    0.045783   \n",
       " 16    0.052393    0.194274    0.060008   -0.265365    0.224684    0.052604   \n",
       " 17    0.000960   -0.015049    0.035032   -0.302504   -0.009573    0.068809   \n",
       " \n",
       "     FabPr_beta  Machn_beta  Cars_beta  Trans_beta  Utils_beta  Rtail_beta  \\\n",
       " 0    -0.079596    0.059396  -0.096599    0.359680   -0.186694   -0.173612   \n",
       " 1    -0.169385   -0.165741  -0.098188    0.516035   -0.095926   -0.218027   \n",
       " 2     0.056913   -0.146828  -0.037885    0.342311    0.160558   -0.306214   \n",
       " 3     0.174931   -0.126617  -0.099087    0.426583    0.248659   -0.212872   \n",
       " 4    -0.036215   -0.116067  -0.069739    0.415369   -0.001827   -0.103224   \n",
       " 5     0.006129   -0.209214   0.017510    0.267639   -0.152664   -0.064473   \n",
       " 6    -0.057465   -0.323009  -0.005332    0.213002    0.047987    0.025864   \n",
       " 7     0.089482   -0.311546   0.059051    0.176066   -0.341798   -0.084498   \n",
       " 8     0.045607   -0.200813   0.123257    0.062301    0.117351   -0.121175   \n",
       " 9     0.046260    0.047262   0.056064   -0.237589    0.161062   -0.121070   \n",
       " 10   -0.156604   -0.290333   0.052358   -0.042293    0.038764   -0.190827   \n",
       " 11   -0.091440   -0.197621   0.006343   -0.093427    0.268483    0.217596   \n",
       " 12    0.041638   -0.333718   0.148877    0.111747    0.098079   -0.039258   \n",
       " 13    0.038605   -0.033080   0.215595   -0.038283    0.205349   -0.251471   \n",
       " 14   -0.154245   -0.265025   0.092599    0.180864    0.169805    0.039022   \n",
       " 15   -0.040393   -0.076913   0.068458   -0.010409    0.126046    0.140092   \n",
       " 16   -0.149024   -0.081609  -0.222379    0.093810   -0.128045   -0.091789   \n",
       " 17    0.003077   -0.147701  -0.025109    0.031772    0.092076   -0.028232   \n",
       " \n",
       "     Finan_beta  Other_beta  \n",
       " 0     0.008411   -0.051763  \n",
       " 1     0.138338    0.073780  \n",
       " 2    -0.135366   -0.167774  \n",
       " 3    -0.056056   -0.106627  \n",
       " 4    -0.146516   -0.115672  \n",
       " 5     0.058317   -0.225747  \n",
       " 6    -0.050209   -0.005159  \n",
       " 7    -0.033215   -0.076200  \n",
       " 8    -0.078927   -0.128026  \n",
       " 9     0.126226    0.705245  \n",
       " 10    0.493427   -0.278624  \n",
       " 11    0.400415   -0.530639  \n",
       " 12    0.217001   -0.091030  \n",
       " 13    0.378019   -0.627553  \n",
       " 14    0.158782   -0.429552  \n",
       " 15    0.229263   -0.276992  \n",
       " 16    0.339104   -0.231581  \n",
       " 17    0.468122   -0.544576  ,\n",
       "       predicted_HML\n",
       " 0          3.879729\n",
       " 1          0.957107\n",
       " 2         -3.564794\n",
       " 3         -1.921280\n",
       " 4         -8.896826\n",
       " ...             ...\n",
       " 1075      -1.427399\n",
       " 1076       6.640172\n",
       " 1077       1.818562\n",
       " 1078      -3.827945\n",
       " 1079       1.568759\n",
       " \n",
       " [1080 rows x 1 columns])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HML Rolling Regression\n",
    "from datetime import timedelta\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "merged_data.columns = merged_data.columns.str.strip()\n",
    "def rolling_regression(data, train_years, test_years):\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "\n",
    "    # List all 17 industry portfolios as regressors\n",
    "    selected_features = ['Food', 'Mines', 'Oil', 'Clths', 'Durbl', 'Chems', 'Cnsum', \n",
    "                         'Cnstr', 'Steel', 'FabPr', 'Machn', 'Cars', 'Trans', 'Utils', \n",
    "                         'Rtail', 'Finan', 'Other']\n",
    "\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "    \n",
    "    results = []\n",
    "    start_year = unique_years[0]\n",
    "\n",
    "    # Perform rolling regression\n",
    "    while start_year + train_years + test_years <= unique_years[-1]:\n",
    "        # Define training and testing periods\n",
    "        train_start = pd.Timestamp(year=start_year, month=1, day=1)\n",
    "        train_end = train_start + timedelta(days=365 * train_years)\n",
    "        test_end = train_end + timedelta(days=365 * test_years)\n",
    "\n",
    "        # Subset the data for training and testing\n",
    "        train_data = data[(data['Date'] >= train_start) & (data['Date'] < train_end)]\n",
    "        test_data = data[(data['Date'] >= train_end) & (data['Date'] < test_end)]\n",
    "\n",
    "        # Fit the model\n",
    "        X_train = train_data[selected_features]\n",
    "        y_train = train_data['HML']\n",
    "        model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "        # Predict on test data\n",
    "        X_test = test_data[selected_features]\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Collect coefficients and predictions\n",
    "        coefficients = model.coef_\n",
    "        results.append({\n",
    "            'train_start': train_start,\n",
    "            'train_end': train_end,\n",
    "            'test_end': test_end,\n",
    "            'coefficients': coefficients,\n",
    "            'predicted_HML': y_pred\n",
    "        })\n",
    "\n",
    "        # Move to the next period\n",
    "        start_year += test_years\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Rolling regression for each scenario\n",
    "results_5_year = rolling_regression(merged_data, 5, 5)\n",
    "results_10_year = rolling_regression(merged_data, 10, 5)\n",
    "results_20_year = rolling_regression(merged_data, 20, 5)\n",
    "\n",
    "def extract_betas_and_predictions(results, industry_portfolios):\n",
    "    betas = []\n",
    "    predicted_HML = []\n",
    "\n",
    "    for index, row in results.iterrows():\n",
    "        beta_dict = {\n",
    "            'train_start': row['train_start'],\n",
    "            'train_end': row['train_end'],\n",
    "            'test_end': row['test_end']\n",
    "        }\n",
    "        \n",
    "        for i, industry in enumerate(industry_portfolios):\n",
    "            beta_dict[f'{industry}_beta'] = row['coefficients'][i]\n",
    "        \n",
    "        betas.append(beta_dict)\n",
    "        predicted_HML.extend(row['predicted_HML'])\n",
    "\n",
    "    betas_df = pd.DataFrame(betas)\n",
    "    predicted_HML_df = pd.DataFrame({'predicted_HML': predicted_HML})\n",
    "\n",
    "    return betas_df, predicted_HML_df\n",
    "\n",
    "industry_portfolios = ['Food', 'Mines', 'Oil', 'Clths', 'Durbl', 'Chems', 'Cnsum', \n",
    "                       'Cnstr', 'Steel', 'FabPr', 'Machn', 'Cars', 'Trans', 'Utils', \n",
    "                       'Rtail', 'Finan', 'Other']\n",
    "\n",
    "# Extracting for each time scheme\n",
    "betas_5_year, predicted_HML_5_year = extract_betas_and_predictions(results_5_year, industry_portfolios)\n",
    "betas_10_year, predicted_HML_10_year = extract_betas_and_predictions(results_10_year, industry_portfolios)\n",
    "betas_20_year, predicted_HML_20_year = extract_betas_and_predictions(results_20_year, industry_portfolios)\n",
    "betas_5_year, predicted_HML_5_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "89303bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         residuals\n",
       " count  1080.000000\n",
       " mean     -0.144324\n",
       " std       2.627564\n",
       " min     -13.519619\n",
       " 25%      -1.541285\n",
       " 50%      -0.288517\n",
       " 75%       1.280076\n",
       " max      18.252588,\n",
       "          residuals\n",
       " count  1020.000000\n",
       " mean     -0.122225\n",
       " std       2.129064\n",
       " min     -10.531912\n",
       " 25%      -1.355265\n",
       " 50%      -0.202789\n",
       " 75%       1.045957\n",
       " max       9.826449,\n",
       "         residuals\n",
       " count  900.000000\n",
       " mean    -0.173789\n",
       " std      2.025429\n",
       " min     -8.039950\n",
       " 25%     -1.424272\n",
       " 50%     -0.282700\n",
       " 75%      0.934058\n",
       " max      6.785557)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Residual\n",
    "def calculate_residuals(data, predicted_HML, train_years, test_years):\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "    residuals = []\n",
    "\n",
    "    start_year = unique_years[0]\n",
    "    predicted_index = 0\n",
    "\n",
    "    while start_year + train_years + test_years <= unique_years[-1]:\n",
    "        # Define the testing period\n",
    "        test_start = pd.Timestamp(year=start_year + train_years, month=1, day=1)\n",
    "        test_end = test_start + timedelta(days=365 * test_years)\n",
    "\n",
    "        # Subset the actual data for the testing period\n",
    "        test_data = data[(data['Date'] >= test_start) & (data['Date'] < test_end)]\n",
    "        actual_HML = test_data['HML'].values\n",
    "\n",
    "        # Calculate residuals\n",
    "        predicted_HML_values = predicted_HML['predicted_HML'].iloc[predicted_index:predicted_index + len(actual_HML)]\n",
    "        residual = actual_HML - predicted_HML_values\n",
    "        residuals.extend(residual)\n",
    "\n",
    "        # Update indices\n",
    "        predicted_index += len(actual_HML)\n",
    "        start_year += test_years\n",
    "\n",
    "    return pd.DataFrame({'residuals': residuals})\n",
    "\n",
    "# Calculate residuals for each rolling scheme\n",
    "residuals_5_year = calculate_residuals(merged_data, predicted_HML_5_year, 5, 5)\n",
    "residuals_10_year = calculate_residuals(merged_data, predicted_HML_10_year, 10, 5)\n",
    "residuals_20_year = calculate_residuals(merged_data, predicted_HML_20_year, 20, 5)\n",
    "\n",
    "residual_summary_5_year = residuals_5_year.describe()\n",
    "residual_summary_10_year = residuals_10_year.describe()\n",
    "residual_summary_20_year = residuals_20_year.describe()\n",
    "\n",
    "residual_summary_5_year, residual_summary_10_year, residual_summary_20_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "459405d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7472.013824415835, 4634.276112332735, 3715.206031934155)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SSE for each time scheme\n",
    "sse_5_year = np.sum(residuals_5_year['residuals'] ** 2)\n",
    "sse_10_year = np.sum(residuals_10_year['residuals'] ** 2)\n",
    "sse_20_year = np.sum(residuals_20_year['residuals'] ** 2)\n",
    "\n",
    "sse_5_year, sse_10_year, sse_20_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f091aadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.84759175456176, 0.8779221245139004, 0.8818784218952873)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HML OOR2\n",
    "def calculate_out_of_sample_r_squared(data, predicted_HML, residuals, train_years, test_years):\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "\n",
    "    total_sum_squares = 0\n",
    "    residual_sum_squares = 0\n",
    "    predicted_index = 0\n",
    "\n",
    "    for start_year in unique_years:\n",
    "        if start_year + train_years + test_years > unique_years[-1]:\n",
    "            break\n",
    "\n",
    "        # Define the testing period\n",
    "        test_start = pd.Timestamp(year=start_year + train_years, month=1, day=1)\n",
    "        test_end = test_start + timedelta(days=365 * test_years)\n",
    "\n",
    "        # Subset the actual data for the testing period\n",
    "        test_data = data[(data['Date'] >= test_start) & (data['Date'] < test_end)]\n",
    "        actual_HML = test_data['HML'].values\n",
    "\n",
    "        # Calculate total sum of squares and residual sum of squares\n",
    "        mean_actual_HML = np.mean(actual_HML)\n",
    "        total_sum_squares += np.sum((actual_HML - mean_actual_HML) ** 2)\n",
    "        residual_sum_squares += np.sum(residuals['residuals'].iloc[predicted_index:predicted_index + len(actual_HML)] ** 2)\n",
    "\n",
    "        # Update indices\n",
    "        predicted_index += len(actual_HML)\n",
    "\n",
    "    return 1 - (residual_sum_squares / total_sum_squares)\n",
    "\n",
    "# Calculate out-of-sample R-squared for each rolling scheme\n",
    "r_squared_5_year = calculate_out_of_sample_r_squared(merged_data, predicted_HML_5_year, residuals_5_year, 5, 5)\n",
    "r_squared_10_year = calculate_out_of_sample_r_squared(merged_data, predicted_HML_10_year, residuals_10_year, 10, 5)\n",
    "r_squared_20_year = calculate_out_of_sample_r_squared(merged_data, predicted_HML_20_year, residuals_20_year, 20, 5)\n",
    "r_squared_5_year, r_squared_10_year, r_squared_20_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e7309706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOM Get Regressors\n",
    "merged_data = pd.merge(industry_portfolio_data, financial_data[['Date', 'MOM']], on='Date')\n",
    "missing_values = merged_data.isnull().sum()\n",
    "X = merged_data.drop(['Date', 'MOM'], axis=1)\n",
    "y = merged_data['MOM']\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating and fitting the Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions and evaluating the model\n",
    "y_pred = rf_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Output the model performance and the missing values information\n",
    "mse, rmse, missing_values\n",
    "# Getting feature importances from the Random Forest model\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4ea0230c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>MOM</td>       <th>  R-squared (uncentered):</th>      <td>   0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   51.23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 Jan 2024</td> <th>  Prob (F-statistic):</th>          <td>6.09e-47</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:24:23</td>     <th>  Log-Likelihood:    </th>          <td> -2642.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   930</td>      <th>  AIC:               </th>          <td>   5296.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   925</td>      <th>  BIC:               </th>          <td>   5320.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Trans</th> <td>   -0.1659</td> <td>    0.042</td> <td>   -3.956</td> <td> 0.000</td> <td>   -0.248</td> <td>   -0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FabPr</th> <td>    0.1316</td> <td>    0.044</td> <td>    3.018</td> <td> 0.003</td> <td>    0.046</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Machn</th> <td>    0.1856</td> <td>    0.039</td> <td>    4.728</td> <td> 0.000</td> <td>    0.109</td> <td>    0.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Finan</th> <td>   -0.2328</td> <td>    0.041</td> <td>   -5.715</td> <td> 0.000</td> <td>   -0.313</td> <td>   -0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Steel</th> <td>   -0.1492</td> <td>    0.030</td> <td>   -4.902</td> <td> 0.000</td> <td>   -0.209</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>311.184</td> <th>  Durbin-Watson:     </th> <td>   1.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2831.555</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.258</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.169</td>  <th>  Cond. No.          </th> <td>    5.56</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       MOM        & \\textbf{  R-squared (uncentered):}      &     0.217   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.213   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       }          &     51.23   \\\\\n",
       "\\textbf{Date:}             & Sat, 06 Jan 2024 & \\textbf{  Prob (F-statistic):}          &  6.09e-47   \\\\\n",
       "\\textbf{Time:}             &     14:24:23     & \\textbf{  Log-Likelihood:    }          &   -2642.8   \\\\\n",
       "\\textbf{No. Observations:} &         930      & \\textbf{  AIC:               }          &     5296.   \\\\\n",
       "\\textbf{Df Residuals:}     &         925      & \\textbf{  BIC:               }          &     5320.   \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Trans} &      -0.1659  &        0.042     &    -3.956  &         0.000        &       -0.248    &       -0.084     \\\\\n",
       "\\textbf{FabPr} &       0.1316  &        0.044     &     3.018  &         0.003        &        0.046    &        0.217     \\\\\n",
       "\\textbf{Machn} &       0.1856  &        0.039     &     4.728  &         0.000        &        0.109    &        0.263     \\\\\n",
       "\\textbf{Finan} &      -0.2328  &        0.041     &    -5.715  &         0.000        &       -0.313    &       -0.153     \\\\\n",
       "\\textbf{Steel} &      -0.1492  &        0.030     &    -4.902  &         0.000        &       -0.209    &       -0.089     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 311.184 & \\textbf{  Durbin-Watson:     } &    1.775  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2831.555  \\\\\n",
       "\\textbf{Skew:}          &  -1.258 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  11.169 & \\textbf{  Cond. No.          } &     5.56  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                    MOM   R-squared (uncentered):                   0.217\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.213\n",
       "Method:                 Least Squares   F-statistic:                              51.23\n",
       "Date:                Sat, 06 Jan 2024   Prob (F-statistic):                    6.09e-47\n",
       "Time:                        14:24:23   Log-Likelihood:                         -2642.8\n",
       "No. Observations:                 930   AIC:                                      5296.\n",
       "Df Residuals:                     925   BIC:                                      5320.\n",
       "Df Model:                           5                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Trans         -0.1659      0.042     -3.956      0.000      -0.248      -0.084\n",
       "FabPr          0.1316      0.044      3.018      0.003       0.046       0.217\n",
       "Machn          0.1856      0.039      4.728      0.000       0.109       0.263\n",
       "Finan         -0.2328      0.041     -5.715      0.000      -0.313      -0.153\n",
       "Steel         -0.1492      0.030     -4.902      0.000      -0.209      -0.089\n",
       "==============================================================================\n",
       "Omnibus:                      311.184   Durbin-Watson:                   1.775\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2831.555\n",
       "Skew:                          -1.258   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.169   Cond. No.                         5.56\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MOM: Linear Regression\n",
    "selected_features = top_5_portfolios['Feature'].tolist()\n",
    "X_selected = merged_data[selected_features]\n",
    "\n",
    "# Splitting data\n",
    "X_train_selected, X_test_selected, y_train_selected, y_test_selected = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating and fitting the Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_selected, y_train_selected)\n",
    "\n",
    "# Making predictions and evaluating the model\n",
    "y_pred_selected = lr_model.predict(X_test_selected)\n",
    "mse_selected = mean_squared_error(y_test_selected, y_pred_selected)\n",
    "rmse_selected = np.sqrt(mse_selected)\n",
    "\n",
    "# Output the model performance\n",
    "mse_selected, rmse_selected\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Creating and fitting the OLS model\n",
    "ols_model = sm.OLS(y_train_selected, X_train_selected).fit()\n",
    "\n",
    "# Printing the summary of the OLS model\n",
    "ols_summary = ols_model.summary()\n",
    "ols_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2a3caf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   train_start  train_end   test_end  Food_beta  Mines_beta  Oil_beta  \\\n",
       " 0   1927-01-01 1931-12-31 1936-12-29   0.215790    0.136198 -0.164491   \n",
       " 1   1932-01-01 1936-12-30 1941-12-29   0.309771   -0.445477  0.240749   \n",
       " 2   1937-01-01 1941-12-31 1946-12-30   1.220014   -0.250833 -0.039079   \n",
       " 3   1942-01-01 1946-12-31 1951-12-30  -0.177578   -0.287085  0.236538   \n",
       " 4   1947-01-01 1951-12-31 1956-12-29  -0.249570    0.193939  0.287711   \n",
       " 5   1952-01-01 1956-12-30 1961-12-29  -0.114166   -0.142376  0.028684   \n",
       " 6   1957-01-01 1961-12-31 1966-12-30   0.567789   -0.278017  0.073915   \n",
       " 7   1962-01-01 1966-12-31 1971-12-30   0.035956    0.051618  0.070730   \n",
       " 8   1967-01-01 1971-12-31 1976-12-29   1.607385   -0.390310  0.298016   \n",
       " 9   1972-01-01 1976-12-30 1981-12-29  -0.343581   -0.067146  0.066215   \n",
       " 10  1977-01-01 1981-12-31 1986-12-30  -0.190772    0.130881  0.241090   \n",
       " 11  1982-01-01 1986-12-31 1991-12-30   0.287754   -0.021651 -0.226516   \n",
       " 12  1987-01-01 1991-12-31 1996-12-29   0.286977    0.106867  0.021406   \n",
       " 13  1992-01-01 1996-12-30 2001-12-29   0.057350    0.040208  0.048206   \n",
       " 14  1997-01-01 2001-12-31 2006-12-30  -0.313334    0.062557 -0.242491   \n",
       " 15  2002-01-01 2006-12-31 2011-12-30  -0.218919    0.193983  0.292041   \n",
       " 16  2007-01-01 2011-12-31 2016-12-29   0.761079    0.012995  0.424545   \n",
       " 17  2012-01-01 2016-12-30 2021-12-29  -0.137801   -0.125399 -0.082776   \n",
       " \n",
       "     Clths_beta  Durbl_beta  Chems_beta  Cnsum_beta  Cnstr_beta  Steel_beta  \\\n",
       " 0    -0.009955    0.240461    0.192783    0.365276   -0.753709    0.009617   \n",
       " 1     0.181344    0.047010    0.440953   -0.208170    0.231972   -0.347388   \n",
       " 2    -0.946421    0.393583    0.058061    0.319519   -0.225791    0.417326   \n",
       " 3    -0.219825    0.086029    0.105405   -0.131335    0.114032    0.138649   \n",
       " 4    -0.275946   -0.107118    0.305843    0.276775    0.055189    0.053814   \n",
       " 5    -0.343877    0.166459    0.147091   -0.089426   -0.154645    0.183618   \n",
       " 6    -0.148233    0.055520    0.038608    0.199640   -0.314955   -0.065956   \n",
       " 7     0.202216    0.268609   -0.217384   -0.254817   -0.066693   -0.308108   \n",
       " 8    -0.309151    0.218071    0.246009   -0.197909   -0.179658    0.018084   \n",
       " 9     0.069268    0.324360    0.143289   -0.141209   -0.529726    0.007492   \n",
       " 10   -0.054846   -0.042964   -0.339350   -0.147956   -0.002631   -0.213947   \n",
       " 11    0.409385    0.035446    0.054165   -0.357739    0.055841   -0.271521   \n",
       " 12   -0.171649    0.094071    0.198220    0.349018    0.030601   -0.058421   \n",
       " 13    0.118787   -0.004132   -0.175083   -0.149606   -0.079133   -0.020437   \n",
       " 14   -0.445457   -0.263803    0.025831    0.198931    0.866885    0.117551   \n",
       " 15    0.020735    0.343277   -0.271839   -0.021384    0.043061   -0.263152   \n",
       " 16   -0.505245   -0.076003   -0.314625   -0.409724    0.202689   -0.018429   \n",
       " 17    0.000768   -0.274946   -0.206769    0.261741    0.230103   -0.091281   \n",
       " \n",
       "     FabPr_beta  Machn_beta  Cars_beta  Trans_beta  Utils_beta  Rtail_beta  \\\n",
       " 0     0.001604   -0.065749   0.044068   -0.152637    0.334733   -0.021854   \n",
       " 1    -0.513259    0.401562  -0.125077   -0.225534   -0.227156    0.285787   \n",
       " 2    -0.197921   -0.541285  -0.004032   -0.199468    0.087240    0.307926   \n",
       " 3     0.068148   -0.230469  -0.056135    0.484101   -0.018604    0.410218   \n",
       " 4    -0.193805    0.006525  -0.111409   -0.015379    0.102666    0.038359   \n",
       " 5     0.211238    0.039571   0.003370   -0.147420   -0.191021    0.187705   \n",
       " 6     0.031368    0.189372  -0.046617   -0.216534   -0.202338    0.047605   \n",
       " 7     0.213457    0.161524   0.075150    0.118216   -0.057306   -0.191684   \n",
       " 8     0.141565    0.324298  -0.077317   -0.239209   -0.448249   -0.657004   \n",
       " 9     0.353456   -0.001174  -0.316563   -0.167516   -0.002219   -0.032833   \n",
       " 10    0.207701    0.070616  -0.106386    0.344534   -0.280564   -0.192592   \n",
       " 11   -0.166668   -0.296394   0.089891   -0.065299   -0.045661   -0.242864   \n",
       " 12    0.135502   -0.222723  -0.170672    0.053023   -0.098356   -0.178205   \n",
       " 13   -0.265045    0.039590  -0.068263    0.292778    0.176620   -0.184124   \n",
       " 14   -0.251677   -0.154711  -0.378375    0.170175   -0.025211   -0.436369   \n",
       " 15    0.352557   -0.170027  -0.349614    0.243734   -0.452921    0.081127   \n",
       " 16   -0.225523    0.062512  -0.140285    0.274058   -0.034058    0.860351   \n",
       " 17   -0.044469    0.038198   0.011870    0.125980    0.077232    0.320443   \n",
       " \n",
       "     Finan_beta  Other_beta  \n",
       " 0    -0.590920    0.089760  \n",
       " 1    -0.397530    0.070796  \n",
       " 2    -0.056442   -0.612989  \n",
       " 3    -0.187821   -0.215633  \n",
       " 4    -0.198322   -0.008144  \n",
       " 5    -0.049243    0.224777  \n",
       " 6    -0.006577    0.176655  \n",
       " 7    -0.243025    0.067886  \n",
       " 8     0.026689   -0.063342  \n",
       " 9     0.118426    0.229867  \n",
       " 10   -0.277304    1.006571  \n",
       " 11    0.175311    0.408957  \n",
       " 12   -0.443520    0.318531  \n",
       " 13    0.059712    0.303937  \n",
       " 14    0.393500    0.099180  \n",
       " 15    0.279220   -0.421694  \n",
       " 16   -0.766710    0.390646  \n",
       " 17   -0.174243    0.035911  ,\n",
       "       predicted_MOM\n",
       " 0         -0.149236\n",
       " 1         -7.558963\n",
       " 2          7.156683\n",
       " 3          4.514412\n",
       " 4          2.015104\n",
       " ...             ...\n",
       " 1075       2.676694\n",
       " 1076      -0.087205\n",
       " 1077      -0.703724\n",
       " 1078       5.527784\n",
       " 1079      -0.925805\n",
       " \n",
       " [1080 rows x 1 columns])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MOM Rolling Regression\n",
    "from datetime import timedelta\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "merged_data.columns = merged_data.columns.str.strip()\n",
    "def rolling_regression(data, train_years, test_years):\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "\n",
    "    # List all 17 industry portfolios as regressors\n",
    "    selected_features = ['Food', 'Mines', 'Oil', 'Clths', 'Durbl', 'Chems', 'Cnsum', \n",
    "                         'Cnstr', 'Steel', 'FabPr', 'Machn', 'Cars', 'Trans', 'Utils', \n",
    "                         'Rtail', 'Finan', 'Other']\n",
    "\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "    \n",
    "    results = []\n",
    "    start_year = unique_years[0]\n",
    "\n",
    "    # Perform rolling regression\n",
    "    while start_year + train_years + test_years <= unique_years[-1]:\n",
    "        # Define training and testing periods\n",
    "        train_start = pd.Timestamp(year=start_year, month=1, day=1)\n",
    "        train_end = train_start + timedelta(days=365 * train_years)\n",
    "        test_end = train_end + timedelta(days=365 * test_years)\n",
    "\n",
    "        # Subset the data for training and testing\n",
    "        train_data = data[(data['Date'] >= train_start) & (data['Date'] < train_end)]\n",
    "        test_data = data[(data['Date'] >= train_end) & (data['Date'] < test_end)]\n",
    "\n",
    "        # Fit the model\n",
    "        X_train = train_data[selected_features]\n",
    "        y_train = train_data['MOM']\n",
    "        model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "        # Predict on test data\n",
    "        X_test = test_data[selected_features]\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Collect coefficients and predictions\n",
    "        coefficients = model.coef_\n",
    "        results.append({\n",
    "            'train_start': train_start,\n",
    "            'train_end': train_end,\n",
    "            'test_end': test_end,\n",
    "            'coefficients': coefficients,\n",
    "            'predicted_MOM': y_pred\n",
    "        })\n",
    "\n",
    "        # Move to the next period\n",
    "        start_year += test_years\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Rolling regression for each scenario\n",
    "results_5_year = rolling_regression(merged_data, 5, 5)\n",
    "results_10_year = rolling_regression(merged_data, 10, 5)\n",
    "results_20_year = rolling_regression(merged_data, 20, 5)\n",
    "\n",
    "def extract_betas_and_predictions(results, industry_portfolios):\n",
    "    betas = []\n",
    "    predicted_MOM = []\n",
    "\n",
    "    for index, row in results.iterrows():\n",
    "        beta_dict = {\n",
    "            'train_start': row['train_start'],\n",
    "            'train_end': row['train_end'],\n",
    "            'test_end': row['test_end']\n",
    "        }\n",
    "        \n",
    "        for i, industry in enumerate(industry_portfolios):\n",
    "            beta_dict[f'{industry}_beta'] = row['coefficients'][i]\n",
    "        \n",
    "        betas.append(beta_dict)\n",
    "        predicted_MOM.extend(row['predicted_MOM'])\n",
    "\n",
    "    betas_df = pd.DataFrame(betas)\n",
    "    predicted_MOM_df = pd.DataFrame({'predicted_MOM': predicted_MOM})\n",
    "\n",
    "    return betas_df, predicted_MOM_df\n",
    "\n",
    "industry_portfolios = ['Food', 'Mines', 'Oil', 'Clths', 'Durbl', 'Chems', 'Cnsum', \n",
    "                       'Cnstr', 'Steel', 'FabPr', 'Machn', 'Cars', 'Trans', 'Utils', \n",
    "                       'Rtail', 'Finan', 'Other']\n",
    "\n",
    "# Extracting for each time scheme\n",
    "betas_5_year, predicted_MOM_5_year = extract_betas_and_predictions(results_5_year, industry_portfolios)\n",
    "betas_10_year, predicted_MOM_10_year = extract_betas_and_predictions(results_10_year, industry_portfolios)\n",
    "betas_20_year, predicted_MOM_20_year = extract_betas_and_predictions(results_20_year, industry_portfolios)\n",
    "betas_5_year, predicted_MOM_5_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fdcafb87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   residuals\n",
       " 0 -10.720764\n",
       " 1   9.148963\n",
       " 2   2.763317\n",
       " 3   2.455588\n",
       " 4  10.264896,\n",
       "    residuals\n",
       " 0  -6.637947\n",
       " 1   8.203690\n",
       " 2   4.258663\n",
       " 3 -10.735683\n",
       " 4  -4.070594,\n",
       "    residuals\n",
       " 0  -5.006253\n",
       " 1  -2.653277\n",
       " 2   2.645168\n",
       " 3   2.858686\n",
       " 4   2.222193)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MOM Residual\n",
    "def calculate_residuals(data, predicted_MOM, train_years, test_years):\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "    residuals = []\n",
    "\n",
    "    start_year = unique_years[0]\n",
    "    predicted_index = 0\n",
    "\n",
    "    while start_year + train_years + test_years <= unique_years[-1]:\n",
    "        # Define the testing period\n",
    "        test_start = pd.Timestamp(year=start_year + train_years, month=1, day=1)\n",
    "        test_end = test_start + timedelta(days=365 * test_years)\n",
    "\n",
    "        # Subset the actual data for the testing period\n",
    "        test_data = data[(data['Date'] >= test_start) & (data['Date'] < test_end)]\n",
    "        actual_MOM = test_data['MOM'].values\n",
    "\n",
    "        # Calculate residuals\n",
    "        predicted_MOM_values = predicted_MOM['predicted_MOM'].iloc[predicted_index:predicted_index + len(actual_MOM)]\n",
    "        residual = actual_MOM - predicted_MOM_values\n",
    "        residuals.extend(residual)\n",
    "\n",
    "        # Update indices\n",
    "        predicted_index += len(actual_MOM)\n",
    "        start_year += test_years\n",
    "\n",
    "    return pd.DataFrame({'residuals': residuals})\n",
    "\n",
    "# Calculate residuals for each rolling scheme\n",
    "residuals_5_year = calculate_residuals(merged_data, predicted_MOM_5_year, 5, 5)\n",
    "residuals_10_year = calculate_residuals(merged_data, predicted_MOM_10_year, 10, 5)\n",
    "residuals_20_year = calculate_residuals(merged_data, predicted_MOM_20_year, 20, 5)\n",
    "\n",
    "residuals_5_year.head(), residuals_10_year.head(), residuals_20_year.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af169f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         residuals\n",
       " count  1080.000000\n",
       " mean     -0.031597\n",
       " std       2.475316\n",
       " min     -13.710342\n",
       " 25%      -1.332233\n",
       " 50%      -0.075307\n",
       " 75%       1.360415\n",
       " max      10.027822,\n",
       "          residuals\n",
       " count  1020.000000\n",
       " mean     -0.098707\n",
       " std       2.148893\n",
       " min     -13.030419\n",
       " 25%      -1.326080\n",
       " 50%      -0.103802\n",
       " 75%       1.141364\n",
       " max       9.186277,\n",
       "         residuals\n",
       " count  900.000000\n",
       " mean    -0.130205\n",
       " std      2.086146\n",
       " min     -8.466385\n",
       " 25%     -1.372565\n",
       " 50%     -0.163566\n",
       " 75%      1.103427\n",
       " max      8.381515)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Residual Summary\n",
    "residual_summary_5_year = residuals_5_year.describe()\n",
    "residual_summary_10_year = residuals_10_year.describe()\n",
    "residual_summary_20_year = residuals_20_year.describe()\n",
    "\n",
    "residual_summary_5_year, residual_summary_10_year, residual_summary_20_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c685b34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28882.64287420492, 20290.76153222713, 15406.472903182286)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SSE for each time scheme\n",
    "sse_5_year = np.sum(residuals_5_year['residuals'] ** 2)\n",
    "sse_10_year = np.sum(residuals_10_year['residuals'] ** 2)\n",
    "sse_20_year = np.sum(residuals_20_year['residuals'] ** 2)\n",
    "\n",
    "sse_5_year, sse_10_year, sse_20_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3cbd33fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6770920604245858, 0.726559645347661, 0.7614872662742465)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MOM OOR2\n",
    "def calculate_out_of_sample_r_squared(data, predicted_MOM, residuals, train_years, test_years):\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y%m')\n",
    "    unique_years = data['Date'].dt.year.unique()\n",
    "\n",
    "    total_sum_squares = 0\n",
    "    residual_sum_squares = 0\n",
    "    predicted_index = 0\n",
    "\n",
    "    for start_year in unique_years:\n",
    "        if start_year + train_years + test_years > unique_years[-1]:\n",
    "            break\n",
    "\n",
    "        # Define the testing period\n",
    "        test_start = pd.Timestamp(year=start_year + train_years, month=1, day=1)\n",
    "        test_end = test_start + timedelta(days=365 * test_years)\n",
    "\n",
    "        # Subset the actual data for the testing period\n",
    "        test_data = data[(data['Date'] >= test_start) & (data['Date'] < test_end)]\n",
    "        actual_MOM = test_data['MOM'].values\n",
    "\n",
    "        # Calculate total sum of squares and residual sum of squares\n",
    "        mean_actual_MOM = np.mean(actual_MOM)\n",
    "        total_sum_squares += np.sum((actual_MOM - mean_actual_MOM) ** 2)\n",
    "        residual_sum_squares += np.sum(residuals['residuals'].iloc[predicted_index:predicted_index + len(actual_MOM)] ** 2)\n",
    "\n",
    "        # Update indices\n",
    "        predicted_index += len(actual_MOM)\n",
    "\n",
    "    return 1 - (residual_sum_squares / total_sum_squares)\n",
    "\n",
    "# Calculate out-of-sample R-squared for each rolling scheme\n",
    "r_squared_5_year = calculate_out_of_sample_r_squared(merged_data, predicted_MOM_5_year, residuals_5_year, 5, 5)\n",
    "r_squared_10_year = calculate_out_of_sample_r_squared(merged_data, predicted_MOM_10_year, residuals_10_year, 10, 5)\n",
    "r_squared_20_year = calculate_out_of_sample_r_squared(merged_data, predicted_MOM_20_year, residuals_20_year, 20, 5)\n",
    "r_squared_5_year, r_squared_10_year, r_squared_20_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e666611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
